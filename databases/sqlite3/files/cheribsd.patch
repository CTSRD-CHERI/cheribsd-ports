diff --git configure configure
index 29ca76b69..f18c6601c 100755
--- configure
+++ configure
@@ -11636,7 +11636,7 @@ fi
 { $as_echo "$as_me:${as_lineno-$LINENO}: checking whether to support FTS3" >&5
 $as_echo_n "checking whether to support FTS3... " >&6; }
 if test "${enable_fts3}" = "yes" ; then
-  OPT_FEATURE_FLAGS="${OPT_FEATURE_FLAGS} -DSQLITE_ENABLE_FTS3"
+  OPT_FEATURE_FLAGS="${OPT_FEATURE_FLAGS} -DSQLITE_ENABLE_FTS3 -DSQLITE_ENABLE_FTS3_PARENTHESIS"
   { $as_echo "$as_me:${as_lineno-$LINENO}: result: yes" >&5
 $as_echo "yes" >&6; }
 else
diff --git create-fossil-manifest create-fossil-manifest
new file mode 100755
index 000000000..07fb567b9
--- /dev/null
+++ create-fossil-manifest
@@ -0,0 +1,15 @@
+#!/bin/sh
+
+set -xe
+# See http://www.wtfpl.net/txt/copying for license details
+# Creates a minimal manifest and manifest.uuid file so sqlite (and fossil) can build
+git rev-parse --git-dir >/dev/null || exit 1
+echo $(git log -1 --format=format:%H) > manifest.uuid.tmp
+echo C $(cat manifest.uuid.tmp) > manifest.tmp
+git log -1 --format=format:%ci%n | sed 's/ [-+].*$//;s/ /T/;s/^/D /' >> manifest.tmp
+# Avoid updating the manifest files if nothing changed:
+cmp --quiet manifest.uuid manifest.uuid.tmp || cp -f manifest.uuid.tmp manifest.uuid
+rm -f manifest.uuid.tmp
+cmp --quiet manifest manifest.tmp || cp -f manifest.tmp manifest
+rm -f manifest.tmp
+
diff --git src/btree.c src/btree.c
index 87bc0058b..6fab28dfd 100644
--- src/btree.c
+++ src/btree.c
@@ -4630,6 +4630,7 @@ static int btreeCursor(
 
   /* Now that no other errors can occur, finish filling in the BtCursor
   ** variables and link the cursor into the BtShared list.  */
+  assert( EIGHT_BYTE_ALIGNMENT(pCur) );
   pCur->pgnoRoot = iTable;
   pCur->iPage = -1;
   pCur->pKeyInfo = pKeyInfo;
@@ -8175,7 +8176,7 @@ static int balance_nonroot(
   */
   szScratch =
        nMaxCells*sizeof(u8*)                       /* b.apCell */
-     + nMaxCells*sizeof(u16)                       /* b.szCell */
+     + ROUND8(nMaxCells*sizeof(u16))               /* b.szCell */
      + pBt->pageSize;                              /* aSpace1 */
 
   assert( szScratch<=7*(int)pBt->pageSize );
@@ -8185,7 +8186,7 @@ static int balance_nonroot(
     goto balance_cleanup;
   }
   b.szCell = (u16*)&b.apCell[nMaxCells];
-  aSpace1 = (u8*)&b.szCell[nMaxCells];
+  aSpace1 = (u8*)ROUND8(&b.szCell[nMaxCells]);
   assert( EIGHT_BYTE_ALIGNMENT(aSpace1) );
 
   /*
@@ -9306,6 +9307,7 @@ int sqlite3BtreeInsert(
         UnpackedRecord r;
         r.pKeyInfo = pCur->pKeyInfo;
         r.aMem = pX->aMem;
+        assert( EIGHT_BYTE_ALIGNMENT(r.aMem) );
         r.nField = pX->nMem;
         r.default_rc = 0;
         r.eqSeen = 0;
diff --git src/build.c src/build.c
index 9be444c3c..adb0f4c07 100644
--- src/build.c
+++ src/build.c
@@ -304,7 +304,7 @@ void sqlite3NestedParse(Parse *pParse, const char *zFormat, ...){
   char *zSql;
   sqlite3 *db = pParse->db;
   u32 savedDbFlags = db->mDbFlags;
-  char saveBuf[PARSE_TAIL_SZ];
+  Parse saveParse;
 
   if( pParse->nErr ) return;
   if( pParse->eParseMode ) return;
@@ -321,13 +321,13 @@ void sqlite3NestedParse(Parse *pParse, const char *zFormat, ...){
     return;
   }
   pParse->nested++;
-  memcpy(saveBuf, PARSE_TAIL(pParse), PARSE_TAIL_SZ);
+  memcpy(PARSE_TAIL(&saveParse), PARSE_TAIL(pParse), PARSE_TAIL_SZ);
   memset(PARSE_TAIL(pParse), 0, PARSE_TAIL_SZ);
   db->mDbFlags |= DBFLAG_PreferBuiltin;
   sqlite3RunParser(pParse, zSql);
   db->mDbFlags = savedDbFlags;
   sqlite3DbFree(db, zSql);
-  memcpy(PARSE_TAIL(pParse), saveBuf, PARSE_TAIL_SZ);
+  memcpy(PARSE_TAIL(pParse), PARSE_TAIL(&saveParse), PARSE_TAIL_SZ);
   pParse->nested--;
 }
 
diff --git src/mem1.c src/mem1.c
index 512ab3747..2cdc30aa5 100644
--- src/mem1.c
+++ src/mem1.c
@@ -117,6 +117,8 @@ static malloc_zone_t* _sqliteZone_;
 
 #endif /* __APPLE__ or not __APPLE__ */
 
+_Static_assert(SQLITE_DEFAULT_ALIGNMENT % sizeof(int64_t) == 0, "");
+
 /*
 ** Like malloc(), but remember the size of the allocation
 ** so that we can find it later using sqlite3MemSize().
@@ -139,8 +141,9 @@ static void *sqlite3MemMalloc(int nByte){
   sqlite3_int64 *p;
   assert( nByte>0 );
   testcase( ROUND8(nByte)!=nByte );
-  p = SQLITE_MALLOC( nByte+8 );
+  p = SQLITE_MALLOC( nByte+SQLITE_DEFAULT_ALIGNMENT );
   if( p ){
+    p += (SQLITE_DEFAULT_ALIGNMENT/sizeof(int64_t))-1;
     p[0] = nByte;
     p++;
   }else{
@@ -165,7 +168,7 @@ static void sqlite3MemFree(void *pPrior){
 #else
   sqlite3_int64 *p = (sqlite3_int64*)pPrior;
   assert( pPrior!=0 );
-  p--;
+  p -= (SQLITE_DEFAULT_ALIGNMENT/sizeof(int64_t));
   SQLITE_FREE(p);
 #endif
 }
@@ -211,9 +214,10 @@ static void *sqlite3MemRealloc(void *pPrior, int nByte){
   sqlite3_int64 *p = (sqlite3_int64*)pPrior;
   assert( pPrior!=0 && nByte>0 );
   assert( nByte==ROUND8(nByte) ); /* EV: R-46199-30249 */
-  p--;
-  p = SQLITE_REALLOC(p, nByte+8 );
+  p -= (SQLITE_DEFAULT_ALIGNMENT/sizeof(int64_t));
+  p = SQLITE_REALLOC(p, nByte+SQLITE_DEFAULT_ALIGNMENT );
   if( p ){
+    p += (SQLITE_DEFAULT_ALIGNMENT/sizeof(int64_t))-1;
     p[0] = nByte;
     p++;
   }else{
diff --git src/mem2.c src/mem2.c
index 04d6298db..2db30d7d5 100644
--- src/mem2.c
+++ src/mem2.c
@@ -42,19 +42,24 @@
 /*
 ** Each memory allocation looks like this:
 **
-**  ------------------------------------------------------------------------
-**  | Title |  backtrace pointers |  MemBlockHdr |  allocation |  EndGuard |
-**  ------------------------------------------------------------------------
+**  --------------------------------------------------------------------------
+**  | Pad | Title | backtrace pointers | MemBlockHdr | allocation | EndGuard |
+**  --------------------------------------------------------------------------
 **
 ** The application code sees only a pointer to the allocation.  We have
 ** to back up from the allocation pointer to find the MemBlockHdr.  The
 ** MemBlockHdr tells us the size of the allocation and the number of
 ** backtrace pointers.  There is also a guard word at the end of the
 ** MemBlockHdr.
+**
+** On CHERI systems we pad the front of the allocation to ensure
+** allocation is sufficently aligned.  We also exclude the EndGuard as it's
+** pointless with bounds.
 */
 struct MemBlockHdr {
   i64 iSize;                          /* Size of this allocation */
   struct MemBlockHdr *pNext, *pPrev;  /* Linked list of all unfreed memory */
+  void *pAllocation;                  /* What malloc allocated */
   char nBacktrace;                    /* Number of backtraces on this alloc */
   char nBacktraceSlots;               /* Available backtrace slots */
   u8 nTitle;                          /* Bytes of title; includes '\0' */
@@ -155,17 +160,31 @@ static struct MemBlockHdr *sqlite3MemsysGetHeader(const void *pAllocation){
   u8 *pU8;
   int nReserve;
 
+#ifndef __CHERI_PURE_CAPABILITY__
   p = (struct MemBlockHdr*)pAllocation;
   p--;
+#else
+  /*
+   * pAllocation's bounds don't contain p so walk the whole list
+   * to find the original.
+   */
+  for ( p = mem->pFirst; p != NULL; p = p->pNext ) {
+    if ( p + 1 == pAllocation )
+      break;
+  }
+  assert( p != NULL )
+#endif
   assert( p->iForeGuard==(int)FOREGUARD );
   nReserve = ROUND8(p->iSize);
   pInt = (int*)pAllocation;
   pU8 = (u8*)pAllocation;
+#ifndef __CHERI_PURE_CAPABILITY__
   assert( pInt[nReserve/sizeof(int)]==(int)REARGUARD );
   /* This checks any of the "extra" bytes allocated due
   ** to rounding up to an 8 byte boundary to ensure 
   ** they haven't been overwritten.
   */
+#endif
   while( nReserve-- > p->iSize ) assert( pU8[nReserve]==0x65 );
   return p;
 }
@@ -247,16 +266,29 @@ static void *sqlite3MemMalloc(int nByte){
   void *p = 0;
   int totalSize;
   int nReserve;
+  int nPad = 0;
   sqlite3_mutex_enter(mem.mutex);
   assert( mem.disallow==0 );
   nReserve = ROUND8(nByte);
-  totalSize = nReserve + sizeof(*pHdr) + sizeof(int) +
+#ifdef __CHERI_PURE_CAPABILITY__
+  nReserve = __builtin_cheri_round_representable_length(nReserve);
+#endif
+  totalSize = nReserve + sizeof(*pHdr) +
                mem.nBacktrace*sizeof(void*) + mem.nTitle;
+#ifdef __CHERI_PURE_CAPABILITY__
+  int roundedSize = __builtin_cheri_round_representable_length(totalSize);
+  nPad = roundedSize - totalSize;
+  totalSize = roundedSize;
+#else
+  totalSize += sizeof(int);	/* EndGuard */
+#endif
   p = malloc(totalSize);
   if( p ){
     z = p;
+    z += nPad;
     pBt = (void**)&z[mem.nTitle];
     pHdr = (struct MemBlockHdr*)&pBt[mem.nBacktrace];
+    pHdr->pAllocation = p;
     pHdr->pNext = 0;
     pHdr->pPrev = mem.pLast;
     if( mem.pLast ){
@@ -286,12 +318,18 @@ static void *sqlite3MemMalloc(int nByte){
     pHdr->iSize = nByte;
     adjustStats(nByte, +1);
     pInt = (int*)&pHdr[1];
+#ifndef __CHERI_PURE_CAPABILITY__
     pInt[nReserve/sizeof(int)] = REARGUARD;
+#endif
     randomFill((char*)pInt, nByte);
     memset(((char*)pInt)+nByte, 0x65, nReserve-nByte);
     p = (void*)pInt;
   }
   sqlite3_mutex_leave(mem.mutex);
+#ifdef __CHERI_PURE_CAPABILITY__
+  if ( p != NULL )
+    p = __builtin_cheri_bounds_set_exact(p, nReserve);
+#endif
   return p; 
 }
 
@@ -302,6 +340,7 @@ static void sqlite3MemFree(void *pPrior){
   struct MemBlockHdr *pHdr;
   void **pBt;
   char *z;
+  void *p;
   assert( sqlite3GlobalConfig.bMemstat || sqlite3GlobalConfig.bCoreMutex==0 
        || mem.mutex!=0 );
   pHdr = sqlite3MemsysGetHeader(pPrior);
@@ -322,12 +361,13 @@ static void sqlite3MemFree(void *pPrior){
     assert( mem.pLast==pHdr );
     mem.pLast = pHdr->pPrev;
   }
+  p = pHdr->pAllocation;
   z = (char*)pBt;
   z -= pHdr->nTitle;
   adjustStats((int)pHdr->iSize, -1);
   randomFill(z, sizeof(void*)*pHdr->nBacktraceSlots + sizeof(*pHdr) +
                 (int)pHdr->iSize + sizeof(int) + pHdr->nTitle);
-  free(z);
+  free(p);
   sqlite3_mutex_leave(mem.mutex);  
 }
 
diff --git src/pager.c src/pager.c
index 44384de5c..c7246827c 100644
--- src/pager.c
+++ src/pager.c
@@ -4828,6 +4828,7 @@ int sqlite3PagerOpen(
   pPager->sjfd = (sqlite3_file*)pPtr;     pPtr += journalFileSize;
   pPager->jfd =  (sqlite3_file*)pPtr;     pPtr += journalFileSize;
   assert( EIGHT_BYTE_ALIGNMENT(pPager->jfd) );
+  pPtr = __builtin_assume_aligned(pPtr, SQLITE_MALLOC_ALIGNMENT);
   memcpy(pPtr, &pPager, sizeof(pPager));  pPtr += sizeof(pPager);
 
   /* Fill in the Pager.zFilename and pPager.zQueryParam fields */
diff --git src/pcache1.c src/pcache1.c
index adbe95395..7d1143c1e 100644
--- src/pcache1.c
+++ src/pcache1.c
@@ -767,7 +767,7 @@ static sqlite3_pcache *pcache1Create(int szPage, int szExtra, int bPurgeable){
   int sz;               /* Bytes of memory required to allocate the new cache */
 
   assert( (szPage & (szPage-1))==0 && szPage>=512 && szPage<=65536 );
-  assert( szExtra < 300 );
+  assert( szExtra < 400 ); // XXX: with CHERI we get szExtra=384 here
 
   sz = sizeof(PCache1) + sizeof(PGroup)*pcache1.separateCache;
   pCache = (PCache1 *)sqlite3MallocZero(sz);
diff --git src/sqliteInt.h src/sqliteInt.h
index 2c893770b..242dd4240 100644
--- src/sqliteInt.h
+++ src/sqliteInt.h
@@ -619,6 +619,9 @@
 ** hack only.
 */
 #ifdef SQLITE_INLINE_MEMCPY
+#ifdef __CHERI_PURE_CAPABILITY__
+#error SQLITE_INLINE_MEMCPY is not allowed when compiling for CheriABI.
+#endif
 # define memcpy(D,S,N) {char*xxd=(char*)(D);const char*xxs=(const char*)(S);\
                         int xxn=(N);while(xxn-->0)*(xxd++)=*(xxs++);}
 #endif
@@ -942,6 +945,14 @@ typedef INT16_TYPE LogEst;
 #define LARGEST_UINT64 (0xffffffff|(((u64)0xffffffff)<<32))
 #define SMALLEST_INT64 (((i64)-1) - LARGEST_INT64)
 
+
+#define REQUIRE_CHERI_ALIGNMENT
+#ifdef REQUIRE_CHERI_ALIGNMENT
+# define SQLITE_DEFAULT_ALIGNMENT (sizeof(void*) < 16 ? 16 : sizeof(void*))
+#else
+# define SQLITE_DEFAULT_ALIGNMENT (sizeof(void*) < 8 ? 8 : sizeof(void*))
+#endif
+
 /*
 ** Round up a number to the next larger multiple of 8.  This is used
 ** to force 8-byte alignment on 64-bit architectures.
@@ -951,18 +962,39 @@ typedef INT16_TYPE LogEst;
 ** ROUND8P() assumes that the argument is already an integer number of
 ** pointers in size, and so it is a no-op on systems where the pointer
 ** size is 8.
+**
+** XXXAR: For CHERI, we change these macros to ensure 16-byte alignement since
+** renaming them would cause too many conflicts
 */
-#define ROUND8(x)     (((x)+7)&~7)
+#if __has_builtin(__builtin_align_up)
+# define ROUND(x, a) __builtin_align_up(x, a)
+#else
+# define ROUND(x, a)     (((x)+(a-1))&~(a-1))
+#endif
+/* XXX: not actually 8 for CHERI */
+#define ROUND8(x) ROUND(x, SQLITE_DEFAULT_ALIGNMENT)
 #if SQLITE_PTRSIZE==8
 # define ROUND8P(x)   (x)
 #else
-# define ROUND8P(x)   (((x)+7)&~7)
+# define ROUND8P(x)   ROUND8(x)
 #endif
 
 /*
 ** Round down to the nearest multiple of 8
 */
-#define ROUNDDOWN8(x) ((x)&~7)
+#if __has_builtin(__builtin_align_down)
+# define ROUNDDOWN(x, a) __builtin_align_down(x, 8)
+#else
+# define ROUNDDOWN(x, a) ((x)&~(a-1))
+#endif
+/* XXX: not actually 8 for CHERI */
+#define ROUNDDOWN8(x) ROUNDDOWN(x, SQLITE_DEFAULT_ALIGNMENT)
+
+#if __has_builtin(__builtin_is_aligned)
+# define ALIGNED_TO(X, A) __builtin_is_aligned(X, A)
+#else
+# define ALIGNED_TO(X, A) ((((char*)(X) - (char*)0)&((A)-1))==0)
+#endif
 
 /*
 ** Assert that the pointer X is aligned to an 8-byte boundary.  This
@@ -972,12 +1004,17 @@ typedef INT16_TYPE LogEst;
 ** Except, if SQLITE_4_BYTE_ALIGNED_MALLOC is defined, then the
 ** underlying malloc() implementation might return us 4-byte aligned
 ** pointers.  In that case, only verify 4-byte alignment.
+**
+** For CHERI support we want 16-byte alignment. We also do this for native to
+** make debugging easier. The macro name is a lie anyway so I don't see why we
+** should't lie just a little bit more.
 */
 #ifdef SQLITE_4_BYTE_ALIGNED_MALLOC
-# define EIGHT_BYTE_ALIGNMENT(X)   ((((uptr)(X) - (uptr)0)&3)==0)
+# define SQLITE_MALLOC_ALIGNMENT 4
 #else
-# define EIGHT_BYTE_ALIGNMENT(X)   ((((uptr)(X) - (uptr)0)&7)==0)
+# define SQLITE_MALLOC_ALIGNMENT SQLITE_DEFAULT_ALIGNMENT
 #endif
+#define EIGHT_BYTE_ALIGNMENT(X) ALIGNED_TO(X, SQLITE_MALLOC_ALIGNMENT)
 
 /*
 ** Disable MMAP on platforms where it is known to not work
@@ -3834,7 +3871,7 @@ struct Parse {
 #define PARSE_HDR_SZ (offsetof(Parse,aTempReg)-offsetof(Parse,zErrMsg)) /* Recursive part w/o aColCache*/
 #define PARSE_RECURSE_SZ offsetof(Parse,sLastToken)    /* Recursive part */
 #define PARSE_TAIL_SZ (sizeof(Parse)-PARSE_RECURSE_SZ) /* Non-recursive part */
-#define PARSE_TAIL(X) (((char*)(X))+PARSE_RECURSE_SZ)  /* Pointer to tail */
+#define PARSE_TAIL(X) (&(X)->sLastToken)  /* Pointer to tail */
 
 /*
 ** Return true if currently inside an sqlite3_declare_vtab() call.
diff --git src/vdbe.c src/vdbe.c
index 2aa4e6df2..c3322d972 100644
--- src/vdbe.c
+++ src/vdbe.c
@@ -268,9 +268,10 @@ static VdbeCursor *allocateCursor(
 
   int nByte;
   VdbeCursor *pCx = 0;
-  nByte = 
-      ROUND8P(sizeof(VdbeCursor)) + 2*sizeof(u32)*nField + 
-      (eCurType==CURTYPE_BTREE?sqlite3BtreeCursorSize():0);
+  size_t basicSize = ROUND8(ROUND8P(sizeof(VdbeCursor)) + 2*sizeof(u32)*nField);
+  assert( EIGHT_BYTE_ALIGNMENT(SQLITE_INT_TO_PTR(basicSize)) );
+  nByte = ROUND8(basicSize + (eCurType==CURTYPE_BTREE?sqlite3BtreeCursorSize():0));
+  assert( EIGHT_BYTE_ALIGNMENT(SQLITE_INT_TO_PTR(nByte)) );
 
   assert( iCur>=0 && iCur<p->nCursor );
   if( p->apCsr[iCur] ){ /*OPTIMIZATION-IF-FALSE*/
@@ -303,8 +304,9 @@ static VdbeCursor *allocateCursor(
   pCx->nField = nField;
   pCx->aOffset = &pCx->aType[nField];
   if( eCurType==CURTYPE_BTREE ){
-    pCx->uc.pCursor = (BtCursor*)
-        &pMem->z[ROUND8P(sizeof(VdbeCursor))+2*sizeof(u32)*nField];
+    assert( EIGHT_BYTE_ALIGNMENT(SQLITE_INT_TO_PTR(basicSize)) );
+    pCx->uc.pCursor = (BtCursor*)&pMem->z[basicSize];
+    assert( EIGHT_BYTE_ALIGNMENT(pCx->uc.pCursor) );
     sqlite3BtreeCursorZero(pCx->uc.pCursor);
   }
   return pCx;
@@ -730,6 +732,7 @@ int sqlite3VdbeExec(
   u64 nProgressLimit;        /* Invoke xProgress() when nVmStep reaches this */
 #endif
   Mem *aMem = p->aMem;       /* Copy of p->aMem */
+  assert( EIGHT_BYTE_ALIGNMENT(aMem) );
   Mem *pIn1 = 0;             /* 1st input operand */
   Mem *pIn2 = 0;             /* 2nd input operand */
   Mem *pIn3 = 0;             /* 3rd input operand */
@@ -1180,6 +1183,7 @@ case OP_Halt: {
     }
     aOp = p->aOp;
     aMem = p->aMem;
+    assert( EIGHT_BYTE_ALIGNMENT(aMem) );
     pOp = &aOp[pcx];
     break;
   }
@@ -4748,6 +4752,7 @@ case OP_SeekGT: {       /* jump, in3, group, ncycle */
     assert( oc!=OP_SeekLT || r.default_rc==+1 );
 
     r.aMem = &aMem[pOp->p3];
+    assert( EIGHT_BYTE_ALIGNMENT(r.aMem) );
 #ifdef SQLITE_DEBUG
     {
       int i;
@@ -5176,6 +5181,7 @@ case OP_Found: {        /* jump, in3, ncycle */
   pC->seekOp = pOp->opcode;
 #endif
   r.aMem = &aMem[pOp->p3];
+  assert( EIGHT_BYTE_ALIGNMENT(r.aMem) );
   assert( pC->eCurType==CURTYPE_BTREE );
   assert( pC->uc.pCursor!=0 );
   assert( pC->isTable==0 );
@@ -6338,6 +6344,7 @@ case OP_IdxInsert: {        /* in2 */
   x.nKey = pIn2->n;
   x.pKey = pIn2->z;
   x.aMem = aMem + pOp->p3;
+  assert( EIGHT_BYTE_ALIGNMENT(x.aMem) );
   x.nMem = (u16)pOp->p4.i;
   rc = sqlite3BtreeInsert(pC->uc.pCursor, &x,
        (pOp->p5 & (OPFLAG_APPEND|OPFLAG_SAVEPOSITION|OPFLAG_PREFORMAT)), 
@@ -6408,6 +6415,7 @@ case OP_IdxDelete: {
   r.nField = (u16)pOp->p3;
   r.default_rc = 0;
   r.aMem = &aMem[pOp->p2];
+  assert( EIGHT_BYTE_ALIGNMENT(r.aMem) );
   rc = sqlite3BtreeIndexMoveto(pCrsr, &r, &res);
   if( rc ) goto abort_due_to_error;
   if( res==0 ){
@@ -6596,6 +6604,8 @@ case OP_IdxGE:  {       /* jump, ncycle */
     r.default_rc = 0;
   }
   r.aMem = &aMem[pOp->p3];
+  assert( EIGHT_BYTE_ALIGNMENT(r.aMem) );
+
 #ifdef SQLITE_DEBUG
   {
     int i;
@@ -7189,6 +7199,8 @@ case OP_Program: {        /* jump */
     pFrame->nChildCsr = pProgram->nCsr;
     pFrame->pc = (int)(pOp - aOp);
     pFrame->aMem = p->aMem;
+    assert( EIGHT_BYTE_ALIGNMENT(pFrame->aMem) );
+
     pFrame->nMem = p->nMem;
     pFrame->apCsr = p->apCsr;
     pFrame->nCursor = p->nCursor;
@@ -7200,6 +7212,7 @@ case OP_Program: {        /* jump */
 #endif
 
     pEnd = &VdbeFrameMem(pFrame)[pFrame->nChildMem];
+    assert( EIGHT_BYTE_ALIGNMENT(aMem) );
     for(pMem=VdbeFrameMem(pFrame); pMem!=pEnd; pMem++){
       pMem->flags = MEM_Undefined;
       pMem->db = db;
@@ -7224,6 +7237,7 @@ case OP_Program: {        /* jump */
   p->nChange = 0;
   p->pFrame = pFrame;
   p->aMem = aMem = VdbeFrameMem(pFrame);
+  assert( EIGHT_BYTE_ALIGNMENT(aMem) );
   p->nMem = pFrame->nChildMem;
   p->nCursor = (u16)pFrame->nChildCsr;
   p->apCsr = (VdbeCursor **)&aMem[p->nMem];
diff --git src/vdbeInt.h src/vdbeInt.h
index b901a0180..daff17f9c 100644
--- src/vdbeInt.h
+++ src/vdbeInt.h
@@ -211,6 +211,7 @@ struct sqlite3_value {
     int nZero;          /* Extra zero bytes when MEM_Zero and MEM_Blob set */
     const char *zPType; /* Pointer type when MEM_Term|MEM_Subtype|MEM_Null */
     FuncDef *pDef;      /* Used only when flags==MEM_Agg */
+    _Alignas(SQLITE_DEFAULT_ALIGNMENT) char ensureAlignment;
   } u;
   char *z;            /* String or BLOB value */
   int n;              /* Number of characters in string value, excluding '\0' */
diff --git src/vdbeapi.c src/vdbeapi.c
index d8fcda96d..77b111df4 100644
--- src/vdbeapi.c
+++ src/vdbeapi.c
@@ -1151,10 +1151,13 @@ static const Mem *columnNullValue(void){
   ** that a Mem structure is located on an 8-byte boundary. To prevent
   ** these assert()s from failing, when building with SQLITE_DEBUG defined
   ** using gcc, we force nullMem to be 8-byte aligned using the magical
-  ** __attribute__((aligned(8))) macro.  */
+  ** __attribute__((aligned(8))) macro.
+  ** For CheriABI, such alignment is increased to 16 bytes to satisfy that the
+  ** returned capability is appropriately aligned for CHERI architectures.
+  */
   static const Mem nullMem 
 #if defined(SQLITE_DEBUG) && defined(__GNUC__)
-    __attribute__((aligned(8))) 
+    __attribute__((aligned(SQLITE_DEFAULT_ALIGNMENT)))
 #endif
     = {
         /* .u          = */ {0},
diff --git src/vdbeaux.c src/vdbeaux.c
index ecbf2d892..32fe3d97b 100644
--- src/vdbeaux.c
+++ src/vdbeaux.c
@@ -2280,6 +2280,7 @@ int sqlite3VdbeNextOpcode(
 void sqlite3VdbeFrameDelete(VdbeFrame *p){
   int i;
   Mem *aMem = VdbeFrameMem(p);
+  assert( EIGHT_BYTE_ALIGNMENT(aMem) );
   VdbeCursor **apCsr = (VdbeCursor **)&aMem[p->nChildMem];
   assert( sqlite3VdbeFrameIsValid(p) );
   for(i=0; i<p->nChildCsr; i++){
@@ -2633,6 +2634,7 @@ void sqlite3VdbeMakeReady(
   */
   x.nNeeded = 0;
   p->aMem = allocSpace(&x, 0, nMem*sizeof(Mem));
+  assert( EIGHT_BYTE_ALIGNMENT(p->aMem) );
   p->aVar = allocSpace(&x, 0, nVar*sizeof(Mem));
   p->apArg = allocSpace(&x, 0, nArg*sizeof(Mem*));
   p->apCsr = allocSpace(&x, 0, nCursor*sizeof(VdbeCursor*));
@@ -2718,6 +2720,7 @@ int sqlite3VdbeFrameRestore(VdbeFrame *pFrame){
   v->aOp = pFrame->aOp;
   v->nOp = pFrame->nOp;
   v->aMem = pFrame->aMem;
+  assert( EIGHT_BYTE_ALIGNMENT(v->aMem) );
   v->nMem = pFrame->nMem;
   v->apCsr = pFrame->apCsr;
   v->nCursor = pFrame->nCursor;
@@ -4113,6 +4116,7 @@ UnpackedRecord *sqlite3VdbeAllocUnpackedRecord(
   p = (UnpackedRecord *)sqlite3DbMallocRaw(pKeyInfo->db, nByte);
   if( !p ) return 0;
   p->aMem = (Mem*)&((char*)p)[ROUND8P(sizeof(UnpackedRecord))];
+  assert( EIGHT_BYTE_ALIGNMENT(p->aMem) );
   assert( pKeyInfo->aSortFlags!=0 );
   p->pKeyInfo = pKeyInfo;
   p->nField = pKeyInfo->nKeyField + 1;
diff --git src/vdbemem.c src/vdbemem.c
index d3cd55ba9..933c7f6c3 100644
--- src/vdbemem.c
+++ src/vdbemem.c
@@ -1417,6 +1417,7 @@ static sqlite3_value *valueNew(sqlite3 *db, struct ValueNewStat4Ctx *p){
           assert( pRec->pKeyInfo->nAllField==nCol );
           assert( pRec->pKeyInfo->enc==ENC(db) );
           pRec->aMem = (Mem *)((u8*)pRec + ROUND8(sizeof(UnpackedRecord)));
+          assert( EIGHT_BYTE_ALIGNMENT(pRec->aMem) );
           for(i=0; i<nCol; i++){
             pRec->aMem[i].flags = MEM_Null;
             pRec->aMem[i].db = db;
@@ -1937,6 +1938,7 @@ void sqlite3Stat4ProbeFree(UnpackedRecord *pRec){
     int i;
     int nCol = pRec->pKeyInfo->nAllField;
     Mem *aMem = pRec->aMem;
+    assert( EIGHT_BYTE_ALIGNMENT(aMem) );
     sqlite3 *db = aMem[0].db;
     for(i=0; i<nCol; i++){
       sqlite3VdbeMemRelease(&aMem[i]);
diff --git src/vdbesort.c src/vdbesort.c
index 3958662cc..1dd4f80d6 100644
--- src/vdbesort.c
+++ src/vdbesort.c
@@ -1740,6 +1740,7 @@ static int vdbeSorterFlushPMA(VdbeSorter *pSorter){
       assert( pTask->list.aMemory==0 || pSorter->list.aMemory!=0 );
 
       aMem = pTask->list.aMemory;
+      assert( EIGHT_BYTE_ALIGNMENT(aMem) );
       pCtx = (void*)pTask;
       pSorter->iPrev = (u8)(pTask - pSorter->aTask);
       pTask->list = pSorter->list;
